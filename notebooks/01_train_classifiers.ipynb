{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 - Setup and Train Classifiers\n",
        "\n",
        "This notebook sets up the environment and trains baseline classifiers (ResNet-50, EfficientNet-B0, ViT) on the GTSRB dataset.\n",
        "\n",
        "**Run this notebook first before other experiments.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/YOUR_USERNAME/adaptive-weather-attacks.git 2>/dev/null || \\\n",
        "    (cd adaptive-weather-attacks && git pull)\n",
        "\n",
        "%cd /content/adaptive-weather-attacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the package in editable mode\n",
        "!pip install -e . -q\n",
        "!pip install torchattacks lpips -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copy dataset to local disk for faster I/O\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "DRIVE_DATA_PATH = '/content/drive/MyDrive/GTSRB_dataset'\n",
        "LOCAL_DATA_PATH = '/content/GTSRB_dataset'\n",
        "\n",
        "if not os.path.exists(LOCAL_DATA_PATH):\n",
        "    print(\"Copying dataset to local disk...\")\n",
        "    shutil.copytree(DRIVE_DATA_PATH, LOCAL_DATA_PATH)\n",
        "    print(\"✅ Dataset copied!\")\n",
        "else:\n",
        "    print(\"✅ Dataset already exists locally\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Verify Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import and verify\n",
        "from src.config import print_config, DEVICE\n",
        "from src.data import get_dataloaders\n",
        "from src.models import get_model, AVAILABLE_MODELS\n",
        "\n",
        "print_config()\n",
        "print(f\"\\nAvailable models: {AVAILABLE_MODELS}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "train_loader, val_loader, test_loader = get_dataloaders('/content/GTSRB_dataset')\n",
        "\n",
        "# Quick verification\n",
        "images, labels = next(iter(test_loader))\n",
        "print(f\"\\nBatch shape: {images.shape}\")\n",
        "print(f\"Labels: {labels[:10]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.models import ModelTrainer, get_model\n",
        "from src.config import CHECKPOINT_DIR\n",
        "\n",
        "# Models to train\n",
        "MODELS_TO_TRAIN = ['resnet50', 'efficientnet_b0']  # Add 'vit' if you have time\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "trained_models = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train ResNet-50\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training ResNet-50\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "resnet = get_model('resnet50', num_classes=43, pretrained=True)\n",
        "trainer = ModelTrainer(resnet, 'resnet50')\n",
        "history = trainer.train(train_loader, val_loader, num_epochs=NUM_EPOCHS)\n",
        "\n",
        "trained_models['resnet50'] = trainer.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train EfficientNet-B0\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training EfficientNet-B0\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "efficientnet = get_model('efficientnet_b0', num_classes=43, pretrained=True)\n",
        "trainer = ModelTrainer(efficientnet, 'efficientnet_b0')\n",
        "history = trainer.train(train_loader, val_loader, num_epochs=NUM_EPOCHS)\n",
        "\n",
        "trained_models['efficientnet_b0'] = trainer.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train ViT (optional - takes longer)\n",
        "TRAIN_VIT = True  # Set to False to skip\n",
        "\n",
        "if TRAIN_VIT:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Training ViT\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    vit = get_model('vit', num_classes=43, pretrained=True)\n",
        "    trainer = ModelTrainer(vit, 'vit', learning_rate=1e-4)  # Lower LR for ViT\n",
        "    history = trainer.train(train_loader, val_loader, num_epochs=NUM_EPOCHS)\n",
        "    \n",
        "    trained_models['vit'] = trainer.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.metrics import compute_accuracy\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TEST SET EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for name, model in trained_models.items():\n",
        "    model.eval()\n",
        "    acc = compute_accuracy(model, test_loader)\n",
        "    print(f\"{name}: {acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Save Checkpoints to Google Drive (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copy checkpoints to Drive for persistence\n",
        "DRIVE_CHECKPOINT_PATH = '/content/drive/MyDrive/adaptive-weather-attacks/checkpoints'\n",
        "os.makedirs(DRIVE_CHECKPOINT_PATH, exist_ok=True)\n",
        "\n",
        "import shutil\n",
        "for ckpt_file in CHECKPOINT_DIR.glob('*.pth'):\n",
        "    dest = os.path.join(DRIVE_CHECKPOINT_PATH, ckpt_file.name)\n",
        "    shutil.copy(ckpt_file, dest)\n",
        "    print(f\"✅ Copied {ckpt_file.name} to Drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Quick Baseline Attack Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.attacks import create_fgsm_attack, evaluate_attack\n",
        "\n",
        "# Test FGSM on ResNet-50\n",
        "model = trained_models['resnet50']\n",
        "fgsm = create_fgsm_attack(model, eps=0.03)\n",
        "\n",
        "results = evaluate_attack(model, fgsm, test_loader, max_batches=10)\n",
        "\n",
        "print(\"\\nFGSM Attack Results (ResNet-50):\")\n",
        "print(f\"  Clean Accuracy: {results['clean_accuracy']:.2f}%\")\n",
        "print(f\"  Adversarial Accuracy: {results['adversarial_accuracy']:.2f}%\")\n",
        "print(f\"  Attack Success Rate: {results['attack_success_rate']:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ✅ Setup Complete!\n",
        "\n",
        "You now have:\n",
        "- Trained classifiers saved in `checkpoints/`\n",
        "- Data loaders ready for experiments\n",
        "\n",
        "**Next:** Run `02_baseline_attacks.ipynb` or skip to `04_vcfg_experiments.ipynb`"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
